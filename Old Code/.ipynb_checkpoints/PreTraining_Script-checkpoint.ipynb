{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da2af98-830d-416f-8502-e9b04e3fd2fc",
   "metadata": {},
   "source": [
    "# Preprocessing DMSP and Black Marble Data for Super-Resolution\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook is the first step in preparing nighttime satellite imagery for super-resolution enhancement using the R-ESRGAN model. Specifically, it focuses on data from the **Defense Meteorological Satellite Program (DMSP)** and **NASA's Black Marble product**.\n",
    "\n",
    "Nighttime lights data from satellites like DMSP have been widely used in research to study urbanization, economic development, population density, and conflict. However, the DMSP dataset is limited by its **low spatial resolution** and various artifacts like cloud cover, sensor noise, and saturation in bright city centers.\n",
    "\n",
    "To address these limitations, this project enhances DMSP images using a super-resolution modelâ€”**R-ESRGAN (Real-Enhanced Super-Resolution Generative Adversarial Network)**â€”which requires training on paired low- and high-resolution images. DMSP data provides the low-resolution input, while NASAâ€™s **Black Marble** dataset (which offers higher-resolution visible light imagery) serves as the target.\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "1. **Download DMSP Nighttime Lights data** for selected dates and regions.\n",
    "2. **Download matching Black Marble images** for the same times and locations.\n",
    "3. **Organize the data into folders** for easy access during training.\n",
    "4. **Patch the raster files** into smaller, uniform tiles for efficient model training.\n",
    "5. **Prepare the data for fine-tuning** a super-resolution model (R-ESRGAN).\n",
    "\n",
    "Each step will be implemented and explained clearly, with emphasis on reproducibility and practical understanding. The goal is to build a robust dataset that can help \"teach\" the R-ESRGAN model how to sharpen and restore low-resolution DMSP imagery using realistic high-resolution examples from Black Marble.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93955cf6-dd5f-45b0-be50-bf0377ccf252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ Imports\n",
    "# ðŸ“š Library Loader: Auto-install missing packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_if_needed(package_name, import_as=None):\n",
    "    \"\"\"Installs the package if it's not already available.\"\"\"\n",
    "    import_name = import_as if import_as else package_name\n",
    "    try:\n",
    "        __import__(import_name)\n",
    "    except ImportError:\n",
    "        print(f\"ðŸ“¦ Installing {package_name}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
    "\n",
    "# Core scientific and geospatial libraries\n",
    "required_packages = [\n",
    "    (\"numpy\", None),\n",
    "    (\"rasterio\", None),\n",
    "    (\"geopandas\", None),\n",
    "    (\"matplotlib\", None),\n",
    "    (\"shapely\", None),\n",
    "    (\"boto3\", None)\n",
    "]\n",
    "\n",
    "for pkg, alias in required_packages:\n",
    "    install_if_needed(pkg, alias)\n",
    "\n",
    "# âœ… Now safe to import everything\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import boto3\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.mask import mask\n",
    "from rasterio.io import MemoryFile\n",
    "from shapely.geometry import box, mapping\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# ðŸŒ Countries to process (must match folder names in the \"Data\" directory)\n",
    "countries_of_interest = [\"Saudi Arabia\", \"Oman\"]\n",
    "\n",
    "# ðŸ“ Base directory and paths\n",
    "base_directory = \".\"  # Adjust if needed\n",
    "shapefile_root = os.path.join(base_directory, \"Data\")\n",
    "\n",
    "# ðŸ“‚ Output directory for processed DMSP files\n",
    "DMSP_data_dir = \"./test_dmsp_download\"\n",
    "bm_output_dir = \"./test_bm_download\"\n",
    "\n",
    "# ðŸ§ª Sampling configuration\n",
    "random_seed = 13492\n",
    "sample_size = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27597f-1677-4f87-9f38-caf1b73de981",
   "metadata": {},
   "source": [
    "## Step 1: Download and Process DMSP Imagery\n",
    "\n",
    "In this step, we automatically download and preprocess **DMSP-OLS nightly visible band data** for a region spanning from **Turkey to Oman**.\n",
    "\n",
    "### ðŸ›°ï¸ What Is DMSP-OLS?\n",
    "The Defense Meteorological Satellite Programâ€™s Operational Linescan System (DMSP-OLS) captures nighttime visible light from the Earth's surface. This data is useful for studying human activity and economic patterns over time, but it suffers from limitations like:\n",
    "- **Low resolution**\n",
    "- **Sensor saturation** in brightly lit urban centers\n",
    "- **Noise from clouds, glare, and sensor artifacts**\n",
    "\n",
    "### ðŸ“ Geographic Scope\n",
    "The bounding box used covers:\n",
    "- Western edge: **Turkey (25Â°E)**\n",
    "- Eastern edge: **Oman/Yemen (63.5Â°E)**\n",
    "- Northern edge: **Black Sea/Southern Turkey (42Â°N)**\n",
    "- Southern edge: **Yemen/Sudan (12Â°N)**\n",
    "\n",
    "This region encompasses much of the Middle East and Eastern Mediterranean.\n",
    "\n",
    "### ðŸ”„ What This Script Does\n",
    "\n",
    "#### **1. Setup**\n",
    "\n",
    "* **Parse command-line arguments**\n",
    "\n",
    "  * `--destination-folder`: Output directory\n",
    "  * `--random-seed`: For reproducible sampling\n",
    "  * `--sample-size`: Number of groups to process\n",
    "\n",
    "* **Install required packages** if not already available:\n",
    "  `boto3`, `rasterio`, `numpy`, `matplotlib`, `shapely`\n",
    "\n",
    "* **Define bounding box for region of interest**\n",
    "  *(Covers from Turkey to Oman)*\n",
    "\n",
    "* **Create required directories**\n",
    "\n",
    "  * Temporary folder: `DMSP_nightly_temp/`\n",
    "  * Output folder: user-specified\n",
    "\n",
    "\n",
    "#### **2. Connect & List Files**\n",
    "\n",
    "* Connect anonymously to NASA S3 bucket: `globalnightlight`\n",
    "* List all objects under prefix `F`\n",
    "* **Filter for `.vis.co.tif` files only**\n",
    "* **Group files by mission + date**\n",
    "\n",
    "  * Format: `Fxx_YYYYMMDD`\n",
    "  * Exclude dates **before Jan 20, 2012**\n",
    "\n",
    "\n",
    "#### **3. Sample & Identify Targets**\n",
    "\n",
    "* Randomly sample group keys (based on `--sample-size`)\n",
    "* Remove any group already processed (already exists in output folder)\n",
    "* **Create list of groups to process**\n",
    "\n",
    "\n",
    "\n",
    "#### **4. Process Each Group**\n",
    "\n",
    "For each selected `group_key`:\n",
    "\n",
    "* Create temp folder: `DMSP_nightly_temp/{group_key}`\n",
    "\n",
    "* List files in S3 folder for that satellite and year\n",
    "\n",
    "* Download:\n",
    "\n",
    "  * `.vis.co.tif` (visible)\n",
    "  * `.flag.co.tif` (quality mask)\n",
    "\n",
    "* **Filter downloaded rasters**\n",
    "\n",
    "  * Must intersect with bounding box\n",
    "  * Crop to ROI\n",
    "  * Median value must be > 1\n",
    "  * Store valid file paths and metadata\n",
    "\n",
    "\n",
    "#### **5. Masking & Enhancement**\n",
    "\n",
    "* For each valid raster:\n",
    "\n",
    "  * Apply `log1p` transform to `vis`\n",
    "  * Decode `flag` band bits to identify:\n",
    "\n",
    "    * Clouds (bit 0 or 10)\n",
    "    * Glare (bit 2)\n",
    "    * No-data (bit 15)\n",
    "  * Mask those pixels with `NaN`\n",
    "  * Save masked raster to **in-memory GeoTIFF**\n",
    "\n",
    "#### **6. Merging & Saving**\n",
    "\n",
    "* Merge all in-memory masked rasters into one mosaic\n",
    "* Write the merged raster to disk as:\n",
    "\n",
    "  ```\n",
    "  Gulf_Countries_{group_key}.tif\n",
    "  ```\n",
    "\n",
    "  (in user-defined output folder)\n",
    "\n",
    "\n",
    "\n",
    "#### **7. Cleanup**\n",
    "\n",
    "* Close all in-memory datasets\n",
    "* Delete temporary folders\n",
    "\n",
    "\n",
    "\n",
    "#### **8. Done**\n",
    "\n",
    "* ðŸŽ‰ Print `Processing complete!`\n",
    "\n",
    "\n",
    "> â„¹ï¸ This script does **not** yet download Black Marble imagery. That will be handled in a subsequent step.\n",
    "\n",
    "Once this step is complete, you will have a cleaned, cloud-free, and glare-masked version of DMSP data saved as GeoTIFFs, ready to pair with higher-resolution images for super-resolution modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25dc03c-babd-45a2-a19e-f51a39fcda2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the DMSP nightly downloader script\n",
    "# Adjust the sample size and destination folder as needed\n",
    "\n",
    "# Run the DMSP nightly downloader from a subfolder\n",
    "# Construct and run the command\n",
    "command = f\"DMSP_Nightly_downloader/dmsp_nightly_downloader.py --destination-folder \\\"{DMSP_data_dir}\\\" --random-seed {random_seed} --sample-size {sample_size}\"\n",
    "%run $command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f3da86-6f39-4d26-b9bf-048dadcd7fd3",
   "metadata": {},
   "source": [
    "## Step 2: Load Shapefiles and Crop DMSP Mosaics\n",
    "\n",
    "In this step, we take the merged DMSP raster (from the earlier download script) and:\n",
    "\n",
    "1. **Load the shapefiles** for each country of interest (e.g., Saudi Arabia, Qatar) from the projectâ€™s `Data` directory.\n",
    "2. **Remove old Gulf_Countries_* files** from the output folder to prevent clutter or naming conflicts.\n",
    "3. **Crop the merged DMSP raster** to the boundary of each selected country using its shapefile geometry.\n",
    "4. **Save the cropped results** using the format `Country_Fnumber_Date.tif`, making it easier to track and use country-level tiles for downstream training or evaluation.\n",
    "\n",
    "This allows for country-specific preparation of the DMSP data, enabling better pairing with high-resolution images (e.g., from Black Marble) during super-resolution model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35468993-5244-4d8a-84b1-908610d7bebb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.mask import mask\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ðŸ“ Load the global shapefile\n",
    "world_shapefile_path = os.path.join(base_directory, 'World_Countries', 'World_Countries_Generalized.shp')\n",
    "world_gdf = gpd.read_file(world_shapefile_path)\n",
    "\n",
    "# ðŸ“€ Filter geometries for target countries\n",
    "country_shapes = {}\n",
    "for country in countries_of_interest:\n",
    "    matched = world_gdf[world_gdf[\"COUNTRY\"] == country]\n",
    "    if matched.empty:\n",
    "        print(f\"âŒ No matching geometry for {country}\")\n",
    "    else:\n",
    "        country_shapes[country] = matched\n",
    "        print(f\"âœ… Loaded geometry for {country}\")\n",
    "\n",
    "# âœ‚ï¸ Crop all for one country before moving on to the next\n",
    "for country, gdf in country_shapes.items():\n",
    "    print(f\"\\nðŸ” Processing all rasters for {country}...\")\n",
    "    for file in os.listdir(DMSP_data_dir):\n",
    "        if file.startswith(\"Gulf_Countries_\") and file.endswith(\".tif\"):\n",
    "            file_path = os.path.join(DMSP_data_dir, file)\n",
    "            group_key = file.replace(\"Gulf_Countries_\", \"\").replace(\".tif\", \"\")\n",
    "\n",
    "            try:\n",
    "                with rasterio.open(file_path) as src:\n",
    "                    out_image, out_transform = mask(\n",
    "                        dataset=src,\n",
    "                        shapes=gdf.geometry,\n",
    "                        crop=True,\n",
    "                        filled=True,\n",
    "                        nodata=np.nan\n",
    "                    )\n",
    "\n",
    "                    out_meta = src.meta.copy()\n",
    "                    out_meta.update({\n",
    "                        \"height\": out_image.shape[1],\n",
    "                        \"width\": out_image.shape[2],\n",
    "                        \"transform\": out_transform\n",
    "                    })\n",
    "\n",
    "                out_name = f\"{country}_{group_key}.tif\"\n",
    "                out_path = os.path.join(DMSP_data_dir, out_name)\n",
    "                with rasterio.open(out_path, \"w\", **out_meta) as dst:\n",
    "                    dst.write(out_image)\n",
    "                print(f\"âœ… Saved: {out_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Could not crop {file} for {country}: {e}\")\n",
    "\n",
    "# ðŸ§¹ Clean-up: delete old Gulf_Countries files *after* all cropping is done\n",
    "print(\"\\nðŸ§¹ Cleaning up old Gulf_Countries files...\")\n",
    "for file in os.listdir(DMSP_data_dir):\n",
    "    if file.startswith(\"Gulf_Countries_\") and file.endswith(\".tif\"):\n",
    "        try:\n",
    "            os.remove(os.path.join(DMSP_data_dir, file))\n",
    "            print(f\"ðŸ—‘ï¸ Deleted old file: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Could not delete {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0cde7-3397-4375-923b-4a7577eee9d8",
   "metadata": {},
   "source": [
    "## Download and Align Black Marble Data with DMSP Dates\n",
    "\n",
    "This script automates the process of downloading Black Marble nighttime light data for a list of countries and aligns it with existing DMSP data. The key steps are:\n",
    "\n",
    "1. **Loop Through Countries**: For each country in `countries_of_interest`, the script identifies all valid DMSP image dates from previously processed files.\n",
    "\n",
    "2. **Download Black Marble**: For each DMSP date, it runs the `Downloader.py` script using the same start and end date to fetch the corresponding VIIRS Black Marble data. Output is saved in a central `test_bm_download` folder.\n",
    "\n",
    "3. **Rename Julian Dates**: Since Black Marble files are saved with Julian dates (e.g., `Qatar_2013222.tif`), the script converts these to standard `YYYYMMDD` format (e.g., `Qatar_20130811.tif`) for consistency and pairing.\n",
    "\n",
    "4. **Cleanup Unmatched Files**: After renaming, it checks whether each Black Marble `.tif` file has a corresponding DMSP file by matching the date suffix. Any unmatched files are deleted.\n",
    "\n",
    "This ensures that only relevant and temporally aligned Black Marble data remains, ready for use in training or validation alongside the DMSP data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a27f708-d8c2-42a8-bbdf-7dad0de06ca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from IPython import get_ipython\n",
    "\n",
    "# ðŸ”§ Configuration\n",
    "bm_token = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImRiYWlzc2EiLCJleHAiOjE3NTIxMjE4MDksImlhdCI6MTc0NjkzNzgwOSwiaXNzIjoiaHR0cHM6Ly91cnMuZWFydGhkYXRhLm5hc2EuZ292IiwiaWRlbnRpdHlfcHJvdmlkZXIiOiJlZGxfb3BzIiwiYWNyIjoiZWRsIiwiYXNzdXJhbmNlX2xldmVsIjozfQ.WmFefwH6kbhFIuaThN6Y8QnBBLOS6DIAYVUcARS3nANL1kpK-dJcOqoCzJ0rxvVMFubJZqYjj_Hhu_u5odd0TSfd_2OA6yD88NDB9-a_GMZZfovlTqm-FGAQbK6EDOhVM_j-GZk1j1AG37Vgmqw5LWjXbi4Lo97xuNFS60l61aRK2G9H6BFIoLlBjqx-BD6MAAsAjqjofAOr2Ku0-SllyIJNgD0LwNCut1odafrBX8QAPtQ9lXKl9ssdxx7bKqgmHOqjckvEGQEaBZGBVsKnGGO2X3U1gYKVlFWdcju372oIerORezDx0RJlu3wRiQjaYEc5cHjVA4o58VgE9H886g\"\n",
    "downloader_dir = \"Black-Marble-Utilities\"\n",
    "downloader_script = \"Downloader.py\"\n",
    "os.makedirs(bm_output_dir, exist_ok=True)\n",
    "\n",
    "# ðŸ—‚ Store original working directory\n",
    "original_cwd = os.getcwd()\n",
    "\n",
    "# ðŸ” Loop through each country\n",
    "os.chdir(downloader_dir)\n",
    "try:\n",
    "    for target_country in countries_of_interest:\n",
    "        # ðŸ—•ï¸ Extract DMSP dates for this country\n",
    "        dmsp_path = os.path.join(original_cwd, DMSP_data_dir)\n",
    "        dmsp_files = [f for f in os.listdir(dmsp_path) if f.startswith(f\"{target_country}_\") and f.endswith(\".tif\")]\n",
    "        valid_dates = sorted(set(f.split(\"_\")[-1].replace(\".tif\", \"\") for f in dmsp_files))\n",
    "\n",
    "        for date_str in valid_dates:\n",
    "            try:\n",
    "                dt = datetime.strptime(date_str, \"%Y%m%d\").date()\n",
    "                date_tag = f\"{dt.strftime('%Y%m%d')}\"  # e.g., 20130125\n",
    "\n",
    "                print(f\"ðŸ“† Downloading Black Marble for {target_country} on {dt}...\")\n",
    "                run_cmd = f'{downloader_script} --start-date {dt} --end-date {dt} --country \"{target_country}\" --destination-folder \"../{bm_output_dir}\" --token \"{bm_token}\"'\n",
    "                get_ipython().run_line_magic(\"run\", run_cmd)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Failed for {target_country} on {date_str}: {e}\")\n",
    "\n",
    "    # ðŸ”„ Rename Julian-dated files to YYYYMMDD format\n",
    "    print(\"\\nðŸ”„ Renaming Black Marble output files from Julian to Gregorian date format...\")\n",
    "    full_bm_path = os.path.join(original_cwd, bm_output_dir)\n",
    "    for fname in os.listdir(full_bm_path):\n",
    "        if fname.endswith(\".tif\"):\n",
    "            parts = fname.replace(\".tif\", \"\").split(\"_\")\n",
    "            if len(parts) == 2 and parts[1].isdigit() and len(parts[1]) == 7:\n",
    "                try:\n",
    "                    julian_date = datetime.strptime(parts[1], \"%Y%j\").strftime(\"%Y%m%d\")\n",
    "                    new_name = f\"{parts[0]}_{julian_date}.tif\"\n",
    "                    os.rename(os.path.join(full_bm_path, fname), os.path.join(full_bm_path, new_name))\n",
    "                    print(f\"âœ… Renamed: {fname} â†’ {new_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ Could not rename {fname}: {e}\")\n",
    "\n",
    "    # ðŸ—‘ï¸ Remove BM files that don't match any DMSP date\n",
    "    print(\"\\nðŸ—‘ï¸ Cleaning up unmatched Black Marble files...\")\n",
    "    for fname in os.listdir(full_bm_path):\n",
    "        if fname.endswith(\".tif\"):\n",
    "            parts = fname.replace(\".tif\", \"\").split(\"_\")\n",
    "            if len(parts) == 2 and parts[1].isdigit():\n",
    "                country = parts[0]\n",
    "                date_suffix = parts[1]\n",
    "                expected_prefixes = [f\"{country}_{sensor}_{date_suffix}.tif\" for sensor in [\"F10\", \"F12\", \"F14\", \"F15\", \"F16\", \"F17\", \"F18\", \"F19\"]]\n",
    "                matches_dmsp = any(os.path.exists(os.path.join(dmsp_path, prefix)) for prefix in expected_prefixes)\n",
    "                if not matches_dmsp:\n",
    "                    try:\n",
    "                        os.remove(os.path.join(full_bm_path, fname))\n",
    "                        print(f\"ðŸ—‘ï¸ Deleted unmatched BM file: {fname}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"âš ï¸ Could not delete {fname}: {e}\")\n",
    "\n",
    "finally:\n",
    "    os.chdir(original_cwd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834227d2-5671-4852-8816-5b8d7dd78ff5",
   "metadata": {},
   "source": [
    "# Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce54111-adb8-45ff-b0b2-6abe756f1d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import glob\n",
    "import tempfile\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "# --- Load the shapefile ---\n",
    "shapefile_path = 'Raster_cropper/Data/World_Countries/World_Countries_Generalized.shp'\n",
    "shapefile = gpd.read_file(shapefile_path)\n",
    "\n",
    "def crop_raster_with_shapefile(raster_path, country_shape, output_path):\n",
    "    print(f\"Cropping raster: {os.path.basename(raster_path)}\")\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        image_data = src.read(1)\n",
    "        country_shape = country_shape.to_crs(src.crs)\n",
    "\n",
    "        out_image, out_transform = mask(\n",
    "            src, [mapping(geom) for geom in country_shape.geometry], crop=True, invert=False\n",
    "        )\n",
    "        out_meta = src.meta.copy()\n",
    "\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": out_image.shape[1],\n",
    "        \"width\": out_image.shape[2],\n",
    "        \"transform\": out_transform\n",
    "    })\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image[0], 1)\n",
    "\n",
    "def crop_all_rasters(raster_dirs, output_dirs, shapefile):\n",
    "    for raster_dir, output_dir in zip(raster_dirs, output_dirs):\n",
    "        raster_files = glob.glob(os.path.join(raster_dir, '*.tif'))\n",
    "\n",
    "        for raster_path in raster_files:\n",
    "            filename = os.path.basename(raster_path)\n",
    "            country_name = filename.split('_')[0].strip()\n",
    "\n",
    "            matching_country = shapefile[\n",
    "                shapefile['COUNTRY'].str.strip().str.lower() == country_name.lower()\n",
    "            ]\n",
    "\n",
    "            if matching_country.empty:\n",
    "                print(f\"âŒ Country '{country_name}' not found in shapefile for file {filename}\")\n",
    "                continue\n",
    "\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "            crop_raster_with_shapefile(raster_path, matching_country, output_path)\n",
    "\n",
    "    print(\"âœ… All cropping operations completed.\")\n",
    "\n",
    "def main():\n",
    "    raster_dirs = [\"./test_dmsp_download\", \"./test_bm_download\"]\n",
    "    output_dirs = [\"./test_dmsp_download\", \"./test_bm_download\"]  # Adjust if you want a separate output location\n",
    "    crop_all_rasters(raster_dirs, output_dirs, shapefile)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3821a-2f4a-4347-99c9-9fe0e576c153",
   "metadata": {},
   "source": [
    "## patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dfaedb-b28f-49ed-b01d-23048b85a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths\n",
    "\n",
    "training_data_path = os.path.join(base_directory, 'training_data')\n",
    "dmsp_output_path = os.path.join(training_data_path, 'DMSP')\n",
    "bm_output_path = os.path.join(training_data_path, 'BM')\n",
    "\n",
    "os.makedirs(dmsp_output_path, exist_ok=True)\n",
    "os.makedirs(bm_output_path, exist_ok=True)\n",
    "\n",
    "# Function to remove the patches folders before processing\n",
    "def remove_patches_folders(output_path):\n",
    "    retries = 5\n",
    "    delay = 1  # 1 second delay\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            if os.path.exists(output_path):\n",
    "                shutil.rmtree(output_path)\n",
    "            break  # Exit the loop if successful\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError: {e}. Retrying in {delay} seconds...\")\n",
    "            time.sleep(delay)\n",
    "            retries -= 1\n",
    "\n",
    "# Function to convert an array to 16-bit\n",
    "def convert_to_16bit(array, source_max_value=None):\n",
    "    if np.all(array == 0) or array.size == 0:\n",
    "        return array.astype('uint16')\n",
    "\n",
    "    if source_max_value is None:\n",
    "        source_max_value = np.nanmax(array)\n",
    "    if source_max_value == 0:\n",
    "        print(\"Maximum value in the array is zero. Cannot scale to 16-bit.\")\n",
    "        return array.astype('uint16')\n",
    "\n",
    "    scale_factor = 65535 / source_max_value\n",
    "    array_16bit = (array * scale_factor).astype('uint16')\n",
    "    return array_16bit\n",
    "\n",
    "# Function to normalize and convert DMSP data\n",
    "def normalize_and_convert_dmsp(array):\n",
    "    max_value = np.nanmax(array)\n",
    "    if max_value == 0:\n",
    "        return array.astype('uint16')\n",
    "    array = (array / max_value) * 255  # Scale to max value of 255\n",
    "    array = np.nan_to_num(array)  # Replace NaNs with zero\n",
    "    return convert_to_16bit(array, 255)\n",
    "\n",
    "# Function to pad array to at least the given shape\n",
    "def pad_array(array, min_shape):\n",
    "    pad_height = max(0, min_shape[0] - array.shape[1])\n",
    "    pad_width = max(0, min_shape[1] - array.shape[2])\n",
    "    padded_array = np.pad(array, ((0, 0), (0, pad_height), (0, pad_width)), mode='constant', constant_values=0)\n",
    "    return padded_array\n",
    "\n",
    "# Function to extract patches and their extents from an array, with padding for BM patches\n",
    "def get_patches(array, src, patch_size):\n",
    "    patches = []\n",
    "    extents = []\n",
    "    for i in range(0, src.height, patch_size[1]):\n",
    "        for j in range(0, src.width, patch_size[0]):\n",
    "            patch = array[:, i:i + patch_size[1], j:j + patch_size[0]]\n",
    "            if patch.shape[1] < patch_size[1] or patch.shape[2] < patch_size[0]:\n",
    "                patch = pad_array(patch, patch_size)\n",
    "            patches.append(patch)\n",
    "            window = Window(j, i, patch_size[0], patch_size[1])\n",
    "            extents.append(list(rasterio.windows.bounds(window, src.transform)))\n",
    "    return patches, extents\n",
    "\n",
    "# Function to crop and resize DMSP data to match BM extents, and ensure 64x64 size\n",
    "def crop_to_extent(src, extent, target_size=(64, 64)):\n",
    "    try:\n",
    "        window = rasterio.windows.from_bounds(*extent, transform=src.transform)\n",
    "\n",
    "        # Clip window to raster bounds\n",
    "        row_off = max(0, int(window.row_off))\n",
    "        col_off = max(0, int(window.col_off))\n",
    "        height = min(int(window.height), src.height - row_off)\n",
    "        width = min(int(window.width), src.width - col_off)\n",
    "\n",
    "        if height <= 0 or width <= 0:\n",
    "            raise ValueError(\"Adjusted window is outside raster bounds.\")\n",
    "\n",
    "        window = Window(col_off, row_off, width, height)\n",
    "\n",
    "        scale_x = target_size[0] / width\n",
    "        scale_y = target_size[1] / height\n",
    "\n",
    "        cropped_resized = src.read(\n",
    "            window=window,\n",
    "            out_shape=(src.count, int(height * scale_y), int(width * scale_x)),\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "        cropped_resized = pad_array(cropped_resized, target_size)\n",
    "        return cropped_resized\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping extent due to read error: {e}\")\n",
    "        return np.zeros((src.count, *target_size), dtype='uint16')\n",
    "\n",
    "# Function to save patches\n",
    "def save_patches(patches, extents, dataset_type, country, date, crs, folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    for i, (patch, extent) in enumerate(zip(patches, extents)):\n",
    "        filename = f\"{country}_{date}_patch_{i:04d}.tif\"\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        new_transform = rasterio.transform.from_bounds(*extent, patch.shape[2], patch.shape[1])\n",
    "\n",
    "        with rasterio.open(filepath, 'w', driver='GTiff', height=patch.shape[1], width=patch.shape[2],\n",
    "                           count=patch.shape[0], dtype=patch.dtype, crs=crs, transform=new_transform) as dst:\n",
    "            dst.write(patch)\n",
    "\n",
    "# Function to process BM and DMSP files\n",
    "def process_files(bm_file, dmsp_file):\n",
    "    country, date = os.path.splitext(os.path.basename(bm_file))[0].rsplit('_', 1)\n",
    "\n",
    "    with rasterio.open(bm_file) as src_bm:\n",
    "        bm_patch_size = (256, 256)\n",
    "        bm_array = src_bm.read()\n",
    "        bm_array = pad_array(bm_array, bm_patch_size)\n",
    "        bm_patches, bm_extents = get_patches(bm_array, src_bm, bm_patch_size)\n",
    "\n",
    "        # Filter patches to ensure they are within the country's shapefile\n",
    "        shapefile_path = 'Raster_cropper/Data/World_Countries/World_Countries_Generalized.shp'\n",
    "        country_shapes = gpd.read_file(shapefile_path)\n",
    "        country_shape = country_shapes[country_shapes['COUNTRY'].str.lower() == country.lower()]\n",
    "        if country_shape.empty:\n",
    "            print(f\"Warning: country shape not found for {country}, keeping all patches.\")\n",
    "        else:\n",
    "            filtered = [\n",
    "                (p, e) for p, e in zip(bm_patches, bm_extents)\n",
    "                if gpd.GeoSeries([box(*e)], crs=src_bm.crs).to_crs(country_shape.crs).intersects(country_shape.unary_union).values[0]\n",
    "            ]\n",
    "            if not filtered:\n",
    "                print(f\"No BM patches inside {country} boundary â€” skipping this file.\")\n",
    "                return\n",
    "            bm_patches, bm_extents = zip(*filtered)\n",
    "        save_patches(bm_patches, bm_extents, \"BM\", country, date, src_bm.crs, bm_output_path)\n",
    "\n",
    "    with rasterio.open(dmsp_file) as src_dmsp:\n",
    "        if src_dmsp.crs != src_bm.crs:\n",
    "            raise ValueError(\"CRS of DMSP does not match CRS of BM\")\n",
    "\n",
    "        dmsp_patches = []\n",
    "        for extent in bm_extents:\n",
    "            cropped_resized = crop_to_extent(src_dmsp, extent)\n",
    "            cropped_resized = normalize_and_convert_dmsp(cropped_resized)\n",
    "            dmsp_patches.append(cropped_resized)\n",
    "\n",
    "        save_patches(dmsp_patches, bm_extents, \"DMSP\", country, date, src_dmsp.crs, dmsp_output_path)\n",
    "\n",
    "# Function to match BM and DMSP files by date and process them\n",
    "def process_all_matched_files():\n",
    "    bm_files = [f for f in os.listdir(bm_output_dir) if f.endswith('.tif')]\n",
    "    dmsp_files = [f for f in os.listdir(DMSP_data_dir) if f.endswith('.tif')]\n",
    "\n",
    "    bm_dates = {}\n",
    "    for f in bm_files:\n",
    "        name, _ = os.path.splitext(f)\n",
    "        parts = name.rsplit('_', 1)\n",
    "        if len(parts) == 2:\n",
    "            country, date = parts\n",
    "            bm_dates[f\"{country.strip()}_{date.strip()}\"] = f  # Maps 'Country_YYYYMMDD' to filename\n",
    "\n",
    "    for dmsp_file in dmsp_files:\n",
    "        parts = os.path.splitext(dmsp_file)[0].split('_')\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "        country = \"_\".join(parts[:-2]).strip()\n",
    "        date = parts[-1].strip()\n",
    "        key = f\"{country}_{date}\"\n",
    "\n",
    "        if key in bm_dates:\n",
    "            bm_path = os.path.join(bm_output_dir, bm_dates[key])\n",
    "            dmsp_path = os.path.join(DMSP_data_dir, dmsp_file)\n",
    "            print(f\"Processing pair: {bm_path} and {dmsp_path}\")\n",
    "            process_files(bm_path, dmsp_path)\n",
    "        else:\n",
    "            print(f\"No matching BM file for DMSP file: {dmsp_file}\")\n",
    "\n",
    "# Call the function to process all matched pairs\n",
    "process_all_matched_files()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd3a17-0131-4e5e-b2ca-bfcdb851b8f4",
   "metadata": {},
   "source": [
    "# Plotting Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f39aaa-9a29-4320-a494-d5761e79bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from rasterio.plot import show\n",
    "from shapely.geometry import box\n",
    "\n",
    "# Define paths to the processed patch directories\n",
    "dmsp_output_path = os.path.join(base_directory, 'training_data', 'DMSP')\n",
    "bm_output_path = os.path.join(base_directory, 'training_data', 'BM')\n",
    "shapefile_path = 'Raster_cropper/Data/World_Countries/World_Countries_Generalized.shp'\n",
    "\n",
    "# Function to plot 10 random DMSP-BM patch pairs with filenames and locations\n",
    "def plot_random_patch_pairs(n=10, save_path=None):\n",
    "    dmsp_files = [f for f in os.listdir(dmsp_output_path) if f.endswith('.tif')]\n",
    "    bm_files = [f for f in os.listdir(bm_output_path) if f.endswith('.tif')]\n",
    "\n",
    "    # Match patch pairs by exact filename\n",
    "    pairs = [(f, f) for f in dmsp_files if f in bm_files]\n",
    "\n",
    "    if not pairs:\n",
    "        print(\"No DMSP-BM patch pairs found to display.\")\n",
    "        return\n",
    "\n",
    "    sample_pairs = random.sample(pairs, min(n, len(pairs)))\n",
    "\n",
    "    fig, axes = plt.subplots(len(sample_pairs), 3, figsize=(18, 3 * len(sample_pairs)))\n",
    "    if len(sample_pairs) == 1:\n",
    "        axes = np.expand_dims(axes, 0)\n",
    "\n",
    "    # Load shapefile once (full world used for country extraction)\n",
    "    world_shape = gpd.read_file(shapefile_path)\n",
    "\n",
    "    for idx, (dmsp_file, bm_file) in enumerate(sample_pairs):\n",
    "        dmsp_path = os.path.join(dmsp_output_path, dmsp_file)\n",
    "        bm_path = os.path.join(bm_output_path, bm_file)\n",
    "\n",
    "        with rasterio.open(dmsp_path) as ds_dmsp:\n",
    "            dmsp_img = ds_dmsp.read(1)\n",
    "            dmsp_bounds = ds_dmsp.bounds\n",
    "        with rasterio.open(bm_path) as ds_bm:\n",
    "            bm_img = ds_bm.read(1)\n",
    "\n",
    "        # DMSP image\n",
    "        axes[idx][0].imshow(dmsp_img, cmap='gray')\n",
    "        axes[idx][0].set_title(f\"DMSP: {dmsp_file}\")\n",
    "        axes[idx][0].axis('off')\n",
    "\n",
    "        # BM image\n",
    "        axes[idx][1].imshow(np.log1p(bm_img), cmap='gray')\n",
    "        axes[idx][1].set_title(f\"BM: {bm_file}\")\n",
    "        axes[idx][1].axis('off')\n",
    "\n",
    "        # Location map\n",
    "        ax_map = axes[idx][2]\n",
    "\n",
    "        # Extract country name from filename\n",
    "        country_name = dmsp_file.split('_')[0].strip()\n",
    "        country_shape = world_shape[world_shape['COUNTRY'].str.strip().str.lower() == country_name.lower()]\n",
    "\n",
    "        if country_shape.empty:\n",
    "            ax_map.set_title(f\"No map for: {country_name}\")\n",
    "            ax_map.axis('off')\n",
    "        else:\n",
    "            country_shape.plot(ax=ax_map, facecolor='none', edgecolor='black')\n",
    "            dmsp_geom = gpd.GeoSeries([box(*dmsp_bounds)], crs=ds_dmsp.crs).to_crs(country_shape.crs)\n",
    "            dmsp_geom.plot(ax=ax_map, facecolor='red', edgecolor='red', alpha=0.5)\n",
    "\n",
    "            # Plot BM patch as X marker at the center\n",
    "            with rasterio.open(bm_path) as ds_bm:\n",
    "                bm_bounds = ds_bm.bounds\n",
    "                bm_center_x = (bm_bounds.left + bm_bounds.right) / 2\n",
    "                bm_center_y = (bm_bounds.top + bm_bounds.bottom) / 2\n",
    "\n",
    "            # Calculate distance between centers (in projected units, typically meters or degrees)\n",
    "            dmsp_center_x = (dmsp_bounds.left + dmsp_bounds.right) / 2\n",
    "            dmsp_center_y = (dmsp_bounds.top + dmsp_bounds.bottom) / 2\n",
    "            center_distance = np.sqrt((dmsp_center_x - bm_center_x) ** 2 + (dmsp_center_y - bm_center_y) ** 2)\n",
    "            print(f\"Patch {dmsp_file} vs {bm_file} center distance: {center_distance:.4f}\")\n",
    "\n",
    "            ax_map.scatter(bm_center_x, bm_center_y, color='blue', marker='x', s=100, label='BM patch')\n",
    "            ax_map.add_patch(plt.Rectangle(\n",
    "                (bm_bounds.left, bm_bounds.bottom),\n",
    "                bm_bounds.right - bm_bounds.left,\n",
    "                bm_bounds.top - bm_bounds.bottom,\n",
    "                linewidth=1.5, edgecolor='blue', facecolor='none'\n",
    "            ))\n",
    "\n",
    "            ax_map.plot([], [], color='red', label='DMSP patch')\n",
    "            ax_map.plot([], [], color='blue', marker='x', linestyle='None', label='BM patch center')\n",
    "            ax_map.add_patch(plt.Rectangle((0, 0), 0, 0, edgecolor='blue', facecolor='none', label='BM patch box'))\n",
    "            ax_map.legend(loc='upper right', fontsize='small')\n",
    "            ax_map.set_title(f\"Location in {country_name}\")\n",
    "            ax_map.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# Automatically call the function when running the notebook\n",
    "plot_random_patch_pairs(n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097d1b3-3b81-41d4-904b-166fcece39a9",
   "metadata": {},
   "source": [
    "## Making the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a59a7f-bbb4-4080-82f9-9b301130b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define input and output folders\n",
    "bm_input_dir = os.path.join(base_directory, 'training_data', 'BM')\n",
    "dmsp_input_dir = os.path.join(base_directory, 'training_data', 'DMSP')\n",
    "\n",
    "bm_output_dir = os.path.join('Real_ESRGAN', 'Real-ESRGAN-For-DMSP', 'datasets', 'NL', 'BM')\n",
    "dmsp_output_dir = os.path.join('Real_ESRGAN', 'Real-ESRGAN-For-DMSP', 'datasets', 'NL', 'DMSP')\n",
    "\n",
    "# Safe deletion with retry\n",
    "def safe_rmtree(folder):\n",
    "    for _ in range(5):\n",
    "        try:\n",
    "            shutil.rmtree(folder)\n",
    "            return\n",
    "        except PermissionError:\n",
    "            print(f\"PermissionError on {folder}. Retrying in 1 sec...\")\n",
    "            time.sleep(1)\n",
    "    print(f\"âŒ Could not delete {folder}. Skipping.\")\n",
    "\n",
    "# Ensure output directories exist and are empty\n",
    "for folder in [bm_output_dir, dmsp_output_dir]:\n",
    "    if os.path.exists(folder):\n",
    "        safe_rmtree(folder)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Convert .tif to 16-bit PNG\n",
    "def convert_tif_to_png_16bit(tif_path, output_dir):\n",
    "    with Image.open(tif_path) as img:\n",
    "        arr = np.array(img)\n",
    "\n",
    "        # Normalize float data and convert to 16-bit unsigned int\n",
    "        if np.issubdtype(arr.dtype, np.floating):\n",
    "            arr = np.nan_to_num(arr)\n",
    "            arr = arr - arr.min()\n",
    "            if arr.max() > 0:\n",
    "                arr = (arr / arr.max()) * 65535\n",
    "            arr = arr.astype(np.uint16)\n",
    "\n",
    "        elif arr.dtype != np.uint16:\n",
    "            arr = arr.astype(np.uint16)\n",
    "\n",
    "        img_16bit = Image.fromarray(arr, mode='I;16')\n",
    "        png_filename = os.path.splitext(os.path.basename(tif_path))[0] + '.png'\n",
    "        img_16bit.save(os.path.join(output_dir, png_filename), format='PNG')\n",
    "\n",
    "# Convert BM patches to 16-bit PNGs only\n",
    "bm_files = glob.glob(os.path.join(bm_input_dir, '*.tif'))\n",
    "for file_path in bm_files:\n",
    "    convert_tif_to_png_16bit(file_path, bm_output_dir)\n",
    "\n",
    "# Convert DMSP patches to 16-bit PNGs only\n",
    "dmsp_files = glob.glob(os.path.join(dmsp_input_dir, '*.tif'))\n",
    "for file_path in dmsp_files:\n",
    "    convert_tif_to_png_16bit(file_path, dmsp_output_dir)\n",
    "\n",
    "print(\"âœ… All .tif patches converted and saved as 16-bit PNGs. No .tif files were copied.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
